{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a13a8d-aa69-4c14-9e60-389bbd90a2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b3809b5-6bef-433e-ab40-2642de6e86fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import h5py\n",
    "import mat73\n",
    "from tqdm import tqdm\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fce8d575-fd4d-4ad5-922e-173a32a964d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.logging.basic_config()\n",
    "logger = logging.getLogger()\n",
    "\n",
    "data_path = pathlib.Path('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c33ec66-808b-41f0-8412-bedb0ef50f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 2764.51it/s]\n",
      "INFO: utils.timeit: Time: 0.3631 seconds\n",
      "INFO: utils.timeit: Time: 0.7204 seconds\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:00<00:00, 9669.13it/s]\n",
      "INFO: utils.timeit: Time: 0.1428 seconds\n",
      "INFO: utils.timeit: Time: 0.1553 seconds\n"
     ]
    }
   ],
   "source": [
    "filename = data_path / 'tmp.hdf5'\n",
    "tmp_path = data_path / 'tmp'\n",
    "tmp_path.mkdir(exist_ok=True)\n",
    "\n",
    "data = {str(i): np.random.normal(size=(5,100,100)) for i in range(1000)}\n",
    "with utils.timeit.timeit():\n",
    "    utils.io.to_hdf(filename, data)\n",
    "with utils.timeit.timeit():\n",
    "    for k, v in data.items():\n",
    "        np.save(tmp_path / f'{k}.npy', v)\n",
    "    \n",
    "data = {}\n",
    "with utils.timeit.timeit():\n",
    "    data = utils.io.from_hdf(filename)\n",
    "data = {}\n",
    "with utils.timeit.timeit():\n",
    "    for path in tmp_path.glob('*.npy'):\n",
    "        data[path.stem] = np.load(path)\n",
    "    \n",
    "filename.unlink(missing_ok=True)\n",
    "shutil.rmtree(tmp_path, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd75ed4-b4fb-4314-ab5a-a33b173ec428",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.DataFrame([{'a': 1}], index=['i'])\n",
    "h['b'] = [np.array([1,2])]\n",
    "h['c'] = [np.array(['a','b'])]\n",
    "d = {\n",
    "    'h': h,\n",
    "    'a': [1,2,3],\n",
    "    'b': np.array([4,5,6]),\n",
    "    'c': np.array(['a','b','c']),\n",
    "    'd': {\n",
    "        'da': (1,2,3),\n",
    "        'db': pd.Series(['a','b','c'], index=[9,8,7]),\n",
    "        'dc': pd.DataFrame({'a': [1,2], 'b':[3,4]}, index=[5,6]),\n",
    "    },\n",
    "    'e': torch.normal(mean=0, std=1, size=(3,4)),\n",
    "    'f': 'abc',\n",
    "    'g': 123,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "323f9368-eb8d-4f06-bdf1-147821777f4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: utils.io: h,    a       b       c                                                                                  \n",
      "i  1  [1, 2]  [a, b]\n",
      "WARNING: py.warnings: /Users/hoyinchau/local_documents/research/utils/utils/io.py:110: PerformanceWarning:               \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['b', 'c'], dtype='object')]\n",
      "\n",
      "  except Exception as err:\n",
      "\n",
      "INFO: utils.io: a, [1, 2, 3]                                                                                             \n",
      "INFO: utils.io: b, [4 5 6]                                                                                               \n",
      "INFO: utils.io: c, ['a' 'b' 'c']                                                                                         \n",
      "ERROR: utils.io: Error when creating dataset with key c: No conversion path for dtype: dtype('<U1')                      \n",
      "INFO: utils.io: d/da, (1, 2, 3)                                                                                          \n",
      "INFO: utils.io: d/db, 9    a                                                                                             \n",
      "8    b\n",
      "7    c\n",
      "dtype: object\n",
      "INFO: utils.io: d/dc,    a  b                                                                                            \n",
      "5  1  3\n",
      "6  2  4\n",
      "INFO: utils.io: e, tensor([[ 0.9206, -0.4589, -0.6477, -0.1202],                                                         \n",
      "        [-1.4995,  0.7833,  1.8056, -0.2757],\n",
      "        [-0.2247,  0.1490,  0.8948,  0.2708]])\n",
      "INFO: utils.io: f, abc                                                                                                   \n",
      "INFO: utils.io: g, 123                                                                                                   \n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 301.44it/s]\n",
      "INFO: utils.timeit: Time: 0.0343 seconds\n",
      "  0%|                                                                                              | 0/6 [00:00<?, ?it/s]INFO: utils.io: h, <utils.io.PData object at 0x2a244b580>\n",
      "INFO: utils.io: d/db, <utils.io.PData object at 0x2a244b040>\n",
      "INFO: utils.io: d/dc, <utils.io.PData object at 0x2a244b250>\n",
      "INFO: utils.io: a, [1 2 3]\n",
      "INFO: utils.io: f, abc\n",
      "INFO: utils.io: g, 123\n",
      "INFO: utils.io: b, <HDF5 dataset \"b\": shape (3,), type \"<i8\">\n",
      "INFO: utils.io: d/da, [1 2 3]\n",
      "INFO: utils.io: e, <HDF5 dataset \"e\": shape (3, 4), type \"<f4\">\n",
      "9it [00:00, 769.41it/s]                                                                                                  \n",
      "INFO: utils.timeit: Time: 0.0176 seconds\n"
     ]
    }
   ],
   "source": [
    "filename = data_path / 'tmp.hdf5'\n",
    "logger.setLevel('INFO')\n",
    "\n",
    "def callback(k, v, logger):\n",
    "    # if isinstance(v, np.ndarray) and not v.dtype.kind in 'biufcS':\n",
    "    #     return v.tolist()\n",
    "    logger.info(f'{k}, {v}')\n",
    "        \n",
    "with utils.timeit.timeit():\n",
    "    utils.io.to_hdf(filename, d, groupname='', callback=callback, errors='log', progress=True)\n",
    "\n",
    "def callback(d, k, v, logger):\n",
    "    logger.info(f'{k}, {v}')\n",
    "    # return f'hello_{k}', v\n",
    "\n",
    "with utils.timeit.timeit():\n",
    "    new_d = utils.io.from_hdf(filename, groupname='', callback=callback, progress=True)\n",
    "\n",
    "# utils.pprint.pprint(utils.io.desc_hdf(filename), verbose=True)\n",
    "# utils.pprint.pprint(dict(sorted(new_d.items())), verbose=True)\n",
    "\n",
    "filename.unlink(missing_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55c140c6-8d38-4971-9b47-9e0ad48cfff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: py.warnings: /var/folders/yb/v18fv6tx4sd9pj5lv36gjd500000gn/T/ipykernel_51909/485574139.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  v = np.array(v)\n",
      "\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:08<00:00,  1.74s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████| 415/415 [00:00<00:00, 23645.13it/s]\n"
     ]
    }
   ],
   "source": [
    "def callback(k, v, logger):\n",
    "    if k in ['exp/holoTargets', 'exp/rois']:\n",
    "        dtype = np.float32 if k == 'exp/holoTargets' else int\n",
    "        v = np.array(v)\n",
    "        if v.ndim == 1 and v.dtype.kind != 'O':\n",
    "            v = v.reshape(1,-1)\n",
    "        v = [np.atleast_1d(vi).astype(dtype) for vi in v]\n",
    "        dtype = h5py.vlen_dtype(dtype)\n",
    "        with h5py.File(hdf5_filename, 'a') as f:\n",
    "            dset = f[exp_name].create_dataset(k, shape=len(v), dtype=dtype)\n",
    "            dset[...] = v\n",
    "        raise utils.io.ItemProcessed\n",
    "\n",
    "    if isinstance(v, np.ndarray):\n",
    "        if np.prod(v.shape) > 0:\n",
    "            try:\n",
    "                v = v.astype(type(v.reshape(-1)[0]))\n",
    "            except Exception:\n",
    "                pass\n",
    "        \n",
    "        try:\n",
    "            v = np.stack(v)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "        return v\n",
    "        \n",
    "    if isinstance(v, list):\n",
    "        arr_v = np.array(v)\n",
    "        if arr_v.dtype.kind in 'biufcS':\n",
    "            return arr_v\n",
    "        \n",
    "    return v\n",
    "    \n",
    "logger.setLevel('INFO') # suppress ERROR level logs\n",
    "\n",
    "hdf5_filename = data_path / 'tmp.hdf5'\n",
    "desc_hdf5_filename = data_path / 'tmp.json'\n",
    "hdf5_filename.unlink(missing_ok=True)\n",
    "desc_hdf5_filename.unlink(missing_ok=True)\n",
    "mat_path = pathlib.Path('/Users/hoyinchau/local_documents/research/ken/V1-perturb/data/experiment/will/mat')\n",
    "\n",
    "for filename in tqdm(sorted(list(mat_path.glob('*.mat')))[:5]):\n",
    "    exp_name = filename.stem.removesuffix('_outfile')\n",
    "    \n",
    "    data = utils.io.loadmat(filename)['out']\n",
    "    \n",
    "    utils.io.to_hdf(hdf5_filename, data, groupname=exp_name, callback=callback, errors='log', progress=False)\n",
    "    \n",
    "utils.io.save(desc_hdf5_filename, utils.io.desc_hdf(hdf5_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed869dbb-0fc4-4fe2-a424-b69c704bed32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:utils]",
   "language": "python",
   "name": "conda-env-utils-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
